{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b8e9b-ac65-40be-ae4a-1582ac0900e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File paths\n",
    "files = {\n",
    "    \"DEM\": \"Filled_DEM.tif\",\n",
    "    \"Flow Accumulation\": \"Flow_Acu_1.tif\",\n",
    "    \"Slope\": \"Slope.tif\",\n",
    "    \"TWI\": \"TWI.tif\",\n",
    "    \"LULC\": \"LULC.tif\",\n",
    "    \"Lineament Density\": \"Lineament_Density.tif\"\n",
    "}\n",
    "\n",
    "# Load and print metadata\n",
    "meta_info = {}\n",
    "\n",
    "for name, path in files.items():\n",
    "    with rasterio.open(path) as src:\n",
    "        print(f\"üìå {name}\")\n",
    "        print(f\"  CRS: {src.crs}\")\n",
    "        print(f\"  Resolution: {src.res}\")\n",
    "        print(f\"  Bounds: {src.bounds}\")\n",
    "        print(f\"  Shape: {src.shape}\")\n",
    "        print()\n",
    "        meta_info[name] = {\n",
    "            \"crs\": src.crs,\n",
    "            \"transform\": src.transform,\n",
    "            \"shape\": src.shape\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40651c-072b-46e4-bbab-03a57bd08bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "\n",
    "with rasterio.open(\"Filled_DEM.tif\") as dem_src:\n",
    "    dem_crs = dem_src.crs\n",
    "    dem_transform = dem_src.transform\n",
    "    dem_shape = dem_src.shape\n",
    "    dem_profile = dem_src.profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f851a44-5c93-4b11-9705-9e0c21948229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_to_dem(src_path, dst_path, dem_crs, dem_transform, dem_shape):\n",
    "    with rasterio.open(src_path) as src:\n",
    "        src_data = src.read(1)\n",
    "        src_nodata = src.nodata\n",
    "        dst_data = np.full(dem_shape, src_nodata if src_nodata is not None else -9999, dtype=src_data.dtype)\n",
    "        \n",
    "        reproject(\n",
    "            source=src_data,\n",
    "            destination=dst_data,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=dem_transform,\n",
    "            dst_crs=dem_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "        \n",
    "        profile = dem_profile.copy()\n",
    "        profile.update({\n",
    "            \"dtype\": dst_data.dtype,\n",
    "            \"count\": 1,\n",
    "            \"nodata\": src_nodata if src_nodata is not None else -9999\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(dst_path, 'w', **profile) as dst:\n",
    "            dst.write(dst_data, 1)\n",
    "\n",
    "# Reproject files\n",
    "reproject_to_dem(\"LULC.tif\", \"LULC_aligned.tif\", dem_crs, dem_transform, dem_shape)\n",
    "reproject_to_dem(\"Lineament_Density.tif\", \"Lineament_Density_aligned.tif\", dem_crs, dem_transform, dem_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459638b8-128d-4106-8e30-fd006bb90b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# ‚úÖ Step 1: Extend the raster list\n",
    "rasters = {\n",
    "    \"DEM\": \"Filled_DEM.tif\",\n",
    "    \"LULC\": \"LULC_aligned.tif\",\n",
    "    \"Lineament Density\": \"Lineament_Density_aligned.tif\",\n",
    "    \"Flow Accumulation\": \"Flow_Acu_1.tif\",\n",
    "    \"Slope\": \"Slope.tif\",\n",
    "    \"TWI\": \"TWI.tif\"\n",
    "}\n",
    "\n",
    "# ‚úÖ Step 2: Set custom color maps and units\n",
    "cmap_dict = {\n",
    "    \"DEM\": \"terrain\",\n",
    "    \"LULC\": \"tab20\",             # categorical\n",
    "    \"Lineament Density\": \"YlGnBu\",\n",
    "    \"Flow Accumulation\": \"cubehelix\",\n",
    "    \"Slope\": \"inferno\",\n",
    "    \"TWI\": \"viridis\"\n",
    "}\n",
    "\n",
    "units = {\n",
    "    \"DEM\": \"meters\",\n",
    "    \"LULC\": \"category ID\",\n",
    "    \"Lineament Density\": \"km/km¬≤\",\n",
    "    \"Flow Accumulation\": \"cells\",\n",
    "    \"Slope\": \"degrees\",\n",
    "    \"TWI\": \"index\"\n",
    "}\n",
    "\n",
    "# ‚úÖ Step 3: Define function to clean and display raster info\n",
    "def display_and_clean_raster(name, path):\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1).astype('float32')\n",
    "        crs = src.crs\n",
    "        shape = src.shape\n",
    "        bounds = src.bounds\n",
    "        transform = src.transform\n",
    "        nodata = src.nodata\n",
    "\n",
    "        # Step 4: Apply cleaning\n",
    "        if nodata is not None:\n",
    "            data[data == nodata] = np.nan\n",
    "        data[data < -1e6] = np.nan\n",
    "        data[data > 1e8] = np.nan  # extreme outlier threshold\n",
    "\n",
    "        # Compute stats\n",
    "        min_val = np.nanmin(data)\n",
    "        max_val = np.nanmax(data)\n",
    "\n",
    "        # Print summary\n",
    "        print(f\"üìå {name}\")\n",
    "        print(f\"  Path: {path}\")\n",
    "        print(f\"  CRS: {crs}\")\n",
    "        print(f\"  Dimensions: {shape}\")\n",
    "        print(f\"  Bounds: {bounds}\")\n",
    "        print(f\"  Transform: {transform}\")\n",
    "        print(f\"  Nodata value: {nodata}\")\n",
    "        print(f\"  Value range: min = {min_val:.2f}, max = {max_val:.2f}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        # Step 5: Visualize\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(data, cmap=cmap_dict[name], interpolation='none')\n",
    "        plt.title(f\"{name} ({units[name]})\")\n",
    "        plt.colorbar(label=units[name])\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        return data\n",
    "\n",
    "# ‚úÖ Step 6: Process all rasters\n",
    "cleaned_data = {}\n",
    "for name, path in rasters.items():\n",
    "    cleaned_data[name] = display_and_clean_raster(name, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46079e48-1719-45b1-800a-92d440ea0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚úÖ VERIFICATION OF CLEANED RASTERS\\n\")\n",
    "\n",
    "# Define a function to check NaNs and valid range\n",
    "def verify_cleaned_raster(name, data, expected_shape=None):\n",
    "    print(f\"üîé {name}\")\n",
    "    # Check shape\n",
    "    if expected_shape is not None:\n",
    "        if data.shape != expected_shape:\n",
    "            print(f\"  ‚ö†Ô∏è Shape mismatch: {data.shape} (expected {expected_shape})\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Shape OK: {data.shape}\")\n",
    "    else:\n",
    "        print(f\"  Shape: {data.shape}\")\n",
    "    \n",
    "    # Check NoData\n",
    "    nan_count = np.isnan(data).sum()\n",
    "    total_count = data.size\n",
    "    nan_percent = (nan_count / total_count) * 100\n",
    "    print(f\"  üï≥Ô∏è NaN count: {nan_count} ({nan_percent:.2f}%)\")\n",
    "\n",
    "    # Check range of remaining values\n",
    "    valid_data = data[~np.isnan(data)]\n",
    "    print(f\"  üî¢ Value range: min = {np.min(valid_data):.2f}, max = {np.max(valid_data):.2f}\")\n",
    "\n",
    "    # Check extreme residuals\n",
    "    if (valid_data < -1e6).any() or (valid_data > 1e8).any():\n",
    "        print(\"  ‚ö†Ô∏è Detected extreme/unexpected values. Further cleaning may be needed.\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ No extreme values detected.\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Use DEM as shape reference\n",
    "ref_shape = cleaned_data[\"DEM\"].shape\n",
    "\n",
    "# Verify each cleaned layer\n",
    "for name, data in cleaned_data.items():\n",
    "    verify_cleaned_raster(name, data, expected_shape=ref_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa19fec-c5a9-49e9-b809-6491c9bab5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import zarr\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Raster file paths\n",
    "raster_paths = {\n",
    "    \"DEM\": \"Filled_DEM.tif\",\n",
    "    \"LULC\": \"LULC_aligned.tif\",\n",
    "    \"Lineament Density\": \"Lineament_Density_aligned.tif\",\n",
    "    \"Flow Accumulation\": \"Flow_Acu_1.tif\",\n",
    "    \"Slope\": \"Slope.tif\",\n",
    "    \"TWI\": \"TWI.tif\"\n",
    "}\n",
    "\n",
    "# Load and clean rasters\n",
    "cleaned_data = {}\n",
    "metadata = {}\n",
    "\n",
    "for name, path in raster_paths.items():\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1).astype(\"float32\")\n",
    "        if src.nodata is not None:\n",
    "            data[data == src.nodata] = np.nan\n",
    "        data[data < -1e6] = np.nan\n",
    "        data[data > 1e8] = np.nan\n",
    "\n",
    "        cleaned_data[name] = data\n",
    "        metadata[name] = {\n",
    "            \"crs\": src.crs.to_string(),\n",
    "            \"transform\": src.transform,\n",
    "            \"shape\": src.shape,\n",
    "            \"bounds\": src.bounds,\n",
    "            \"nodata\": src.nodata\n",
    "        }\n",
    "\n",
    "\n",
    "# Stack layers in order\n",
    "layers_to_stack = [\n",
    "    cleaned_data[\"DEM\"],\n",
    "    cleaned_data[\"Slope\"],\n",
    "    cleaned_data[\"Flow Accumulation\"],\n",
    "    cleaned_data[\"TWI\"],\n",
    "    cleaned_data[\"Lineament Density\"],\n",
    "   \n",
    "]\n",
    "\n",
    "static_stack = np.stack(layers_to_stack, axis=0)  # shape: (bands, H, W)\n",
    "\n",
    "# Save to Zarr with full metadata\n",
    "zarr_store = zarr.open(\"1_Static_data_alligned.zarr\", mode='w',\n",
    "                       shape=static_stack.shape,\n",
    "                       chunks=(1, *static_stack.shape[1:]),\n",
    "                       dtype='float32')\n",
    "\n",
    "zarr_store[:] = static_stack\n",
    "zarr_store.attrs[\"band_names\"] = [\n",
    "    \"DEM\", \"Slope\", \"Flow Accumulation\", \"TWI\", \"Lineament Density\"\n",
    "]\n",
    "zarr_store.attrs[\"crs\"] = metadata[\"DEM\"][\"crs\"]\n",
    "zarr_store.attrs[\"transform\"] = tuple(metadata[\"DEM\"][\"transform\"])\n",
    "zarr_store.attrs[\"bounds\"] = tuple(metadata[\"DEM\"][\"bounds\"])\n",
    "zarr_store.attrs[\"nodata\"] = metadata[\"DEM\"][\"nodata\"]\n",
    "\n",
    "print(\"‚úÖ Saved to Zarr with full metadata\")\n",
    "print(f\"üìê Shape: {static_stack.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb39103-1801-4ed2-8372-202b88b047dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "import zarr\n",
    "from affine import Affine\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 1. Load the stacked Zarr array\n",
    "zarr_path = \"1_Static_data_alligned.zarr\"\n",
    "stack = zarr.load(zarr_path)  # shape: (7, rows, cols)\n",
    "metadata = zarr.open(zarr_path).attrs\n",
    "\n",
    "# Wrap it into an xarray DataArray\n",
    "da = xr.DataArray(\n",
    "    stack,\n",
    "    dims=[\"band\", \"y\", \"x\"],\n",
    "    name=\"static_data\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 2. Extract the DEM band (band 0)\n",
    "dem = da.isel(band=0)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 3. Read transform and bounds from Zarr metadata\n",
    "transform_tuple = metadata[\"transform\"]\n",
    "transform = Affine(*transform_tuple)\n",
    "\n",
    "bounds = metadata[\"bounds\"]\n",
    "crs = metadata[\"crs\"]\n",
    "nodata_val = metadata[\"nodata\"]\n",
    "\n",
    "# Get shape\n",
    "height, width = dem.shape\n",
    "\n",
    "# Generate coordinates using the affine transform\n",
    "x_coords = (np.arange(width) + 0.5) * transform.a + transform.c\n",
    "y_coords = (np.arange(height) + 0.5) * transform.e + transform.f\n",
    "\n",
    "# Assign coordinates to the DataArray\n",
    "dem = dem.assign_coords(x=x_coords, y=y_coords)\n",
    "dem = dem.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=False)\n",
    "dem = dem.rio.write_crs(crs, inplace=False)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 4. Optional: Set nodata if needed\n",
    "if nodata_val is not None:\n",
    "    dem = dem.where(dem != nodata_val)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 5. Print Metadata Summary\n",
    "print(\"üìå DEM Metadata Info\")\n",
    "print(f\"CRS            : {dem.rio.crs}\")\n",
    "print(f\"Resolution     : {dem.rio.resolution()}\")\n",
    "print(f\"Bounds         : {dem.rio.bounds()}\")\n",
    "print(f\"Shape          : {dem.shape}\")\n",
    "print(f\"NoData value   : {nodata_val}\")\n",
    "print(f\"Min Elevation  : {float(dem.min()):.2f}\")\n",
    "print(f\"Max Elevation  : {float(dem.max()):.2f}\")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# 6. Visualize DEM\n",
    "plt.figure(figsize=(8, 6))\n",
    "dem.plot(cmap='terrain')\n",
    "plt.title(\"DEM from Zarr (with Embedded Metadata)\")\n",
    "plt.xlabel(\"Longitude or X (map units)\")\n",
    "plt.ylabel(\"Latitude or Y (map units)\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e11995-ed3e-40d4-9b8e-cfe24bd3f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "# Get the shape\n",
    "height, width = dem.shape\n",
    "\n",
    "# Compute the centroid pixel index\n",
    "centroid_row = height // 2\n",
    "centroid_col = width // 2\n",
    "\n",
    "# Extract x/y coordinate values using DataArray's coords\n",
    "centroid_x = float(dem.x[centroid_col].values)\n",
    "centroid_y = float(dem.y[centroid_row].values)\n",
    "\n",
    "print(\"üìç DEM Centroid in Projected CRS:\")\n",
    "print(f\"X (Easting) : {centroid_x}\")\n",
    "print(f\"Y (Northing): {centroid_y}\")\n",
    "\n",
    "# Get CRS from DataArray\n",
    "projected_crs = dem.rio.crs\n",
    "\n",
    "# Set up transformer to WGS84 (EPSG:4326)\n",
    "transformer = Transformer.from_crs(projected_crs, \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Convert to lat/lon\n",
    "lon, lat = transformer.transform(centroid_x, centroid_y)\n",
    "\n",
    "print(\"üåç Converted Centroid Coordinates (WGS84):\")\n",
    "print(f\"Longitude: {lon}\")\n",
    "print(f\"Latitude : {lat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0fb39-80ef-4de1-b0bd-990f57aef2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from affine import Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73863eaa-8c8c-4b0e-a0eb-33f64c37f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Prepare rainfall files (2014‚Äì2024 only)\n",
    "# -----------------------\n",
    "rainfall_dir = r\"F:\\browse folder directory where data is present\"\n",
    "rainfall_files = sorted(glob.glob(os.path.join(rainfall_dir, \"RF25_ind*_rfp25.nc\")))\n",
    "\n",
    "# Filter only 1994‚Äì2023 files\n",
    "selected_files = [f for f in rainfall_files if \"1994\" <= os.path.basename(f)[8:12] <= \"2023\"]\n",
    "print(f\"üóÇ Total files selected: {len(selected_files)}\")\n",
    "\n",
    "print(f\"üóÇ Selected files: {[os.path.basename(f) for f in selected_files]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa9a03-8893-437b-b277-d39adbe6c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyproj import Transformer\n",
    "\n",
    "# === Step 1: Extract DEM centroid (WGS84) ===\n",
    "height, width = dem.shape\n",
    "centroid_row = height // 2\n",
    "centroid_col = width // 2\n",
    "centroid_x = float(dem.x[centroid_col].values)\n",
    "centroid_y = float(dem.y[centroid_row].values)\n",
    "projected_crs = dem.rio.crs\n",
    "\n",
    "transformer = Transformer.from_crs(projected_crs, \"EPSG:4326\", always_xy=True)\n",
    "lon, lat = transformer.transform(centroid_x, centroid_y)\n",
    "\n",
    "print(\"üåç DEM Centroid in WGS84:\")\n",
    "print(f\"Longitude: {lon}\")\n",
    "print(f\"Latitude : {lat}\")\n",
    "\n",
    "# === Step 2: Extract rainfall at centroid across all years ===\n",
    "rainfall_series = []\n",
    "time_series = []\n",
    "\n",
    "for file in selected_files:\n",
    "    print(f\"\\nüîÑ Processing: {os.path.basename(file)}\")\n",
    "    ds = xr.open_dataset(file)\n",
    "\n",
    "    print(\"üì¶ Variables in dataset:\", list(ds.data_vars.keys()))\n",
    "\n",
    "    # Flexible keys\n",
    "    lat_key = 'lat' if 'lat' in ds.coords else 'LATITUDE'\n",
    "    lon_key = 'lon' if 'lon' in ds.coords else 'LONGITUDE'\n",
    "    rain_key = 'rf' if 'rf' in ds.data_vars else 'RAINFALL'\n",
    "    time_key = 'TIME' if 'TIME' in ds.coords else 'time'\n",
    "\n",
    "    lat_vals = ds[lat_key].values\n",
    "    lon_vals = ds[lon_key].values\n",
    "\n",
    "    # Nearest grid index to centroid\n",
    "    lat_idx = np.abs(lat_vals - lat).argmin()\n",
    "    lon_idx = np.abs(lon_vals - lon).argmin()\n",
    "\n",
    "    try:\n",
    "        rf_daily = ds[rain_key].isel({lat_key: lat_idx, lon_key: lon_idx})\n",
    "        rainfall_series.append(rf_daily.values)\n",
    "        time_series.append(pd.to_datetime(ds[time_key].values))\n",
    "        print(\"‚úÖ Extracted daily rainfall (first 5):\", rf_daily.values[:5])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to extract rainfall: {e}\")\n",
    "\n",
    "# === Step 3: Cross-Verification ===\n",
    "print(\"\\nüîé Cross-Verification Summary:\")\n",
    "print(f\"üü¢ Years Processed     : {len(rainfall_series)}\")\n",
    "print(f\"üü¢ Total Days Extracted: {sum(len(r) for r in rainfall_series)}\")\n",
    "print(f\"üü¢ Sample Years with Non-Zero Rainfall:\")\n",
    "\n",
    "for i, rf in enumerate(rainfall_series):\n",
    "    if np.any(rf > 0):\n",
    "        print(f\"  ‚úÖ Year {i + 1994}: {rf[:5]} ...\")\n",
    "\n",
    "# === Step 4: Flatten + Stack for Zarr Output ===\n",
    "rainfall_series_flat = np.concatenate(rainfall_series)\n",
    "time_series_flat = np.concatenate(time_series)\n",
    "\n",
    "# Create DataArray\n",
    "rainfall_da = xr.DataArray(\n",
    "    rainfall_series_flat,\n",
    "    coords={\"time\": time_series_flat},\n",
    "    dims=[\"time\"],\n",
    "    name=\"rainfall\"\n",
    ")\n",
    "\n",
    "# Create Dataset and Save\n",
    "rainfall_ds = xr.Dataset({\"rainfall\": rainfall_da})\n",
    "\n",
    "output_zarr = \"2_Dynamic_rainfall_centroid_1994_2023.zarr\"\n",
    "rainfall_ds.to_zarr(output_zarr, mode=\"w\")\n",
    "\n",
    "print(f\"\\nüíæ Saved rainfall time series to: {output_zarr}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Deep_Learning)",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
